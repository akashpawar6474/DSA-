Problem Description (sc pb)

Given a 2D integer matrix A of size N x N find a B x B submatrix where B<= N and B>= 1, such that sum of all the elements in submatrix is maximum.



Problem Constraints

1 <= N <= 103.

1 <= B <= N

-102 <= A[i][j] <= 102.



Input Format

First arguement is an 2D integer matrix A.

Second argument is an integer B.



Output Format

Return a single integer denoting the maximum sum of submatrix of size B x B.



Example Input

Input 1:

 A = [
        [1, 1, 1, 1, 1]
        [2, 2, 2, 2, 2]
        [3, 8, 6, 7, 3]
        [4, 4, 4, 4, 4]
        [5, 5, 5, 5, 5]
     ]
 B = 3
Input 2:

 A = [
        [2, 2]
        [2, 2]
    ]
 B = 2


Example Output

Output 1:

 48
Output 2:

 8
 ---------------------------------------------
 class Solution:
    # @param A : list of list of integers
    # @param B : integer
    # @return an integer
    def solve(self, A, B):
        """
        we have fixed diff bw top left and bottom bottomRight
        so we can just calculate bottom right row and col idx at constant time
        
        tc = O(n ^ 2 + n ^ 2)
        sc = constant
        """
        maxSum = float('-inf')

        n = len(A)
        m = len(A[0])

        for rowIdx in range(n):
            for colIdx in range(1,m):
                A[rowIdx][colIdx] = A[rowIdx][colIdx] + A[rowIdx][colIdx - 1]
        
        for colIdx in range(m):
            for rowIdx in range(1,n):
                A[rowIdx][colIdx] = A[rowIdx][colIdx] + A[rowIdx - 1][colIdx]

        for a1 in range(n - B + 1):
            for b1 in range(n - B + 1):
                a2 = a1 + B - 1
                b2 = b1 + B - 1
                tsum = A[a2][b2]
                if b1 > 0:
                    tsum -= A[a2][b1 - 1]
                if a1 > 0:
                    tsum -= A[a1 - 1][b2]
                if a1 > 0 and b1 > 0:
                    tsum += A[a1 - 1][b1 - 1]
                maxSum = max(maxSum,tsum)
        return maxSum

    def bruteForce(self,A,B):
        """
        first of all calculate prefix sum matrix

        then our topLeftRowIdx will go from 0 to n - B
                topLeftColIdx will go from 0 to n - B

                bottomRightRowIdx will go from n - b to n - 1
                bottomRightColIdx will go from n - b to n - 1
            
        then just keep track of max sum among them
        """
        maxSum = float('-inf')

        n = len(A)
        m = len(A[0])

        for rowIdx in range(n):
            for colIdx in range(1,m):
                A[rowIdx][colIdx] = A[rowIdx][colIdx] + A[rowIdx][colIdx - 1]
        
        for colIdx in range(m):
            for rowIdx in range(1,n):
                A[rowIdx][colIdx] = A[rowIdx][colIdx] + A[rowIdx - 1][colIdx]

        for a1 in range(0,n - B + 1):
            for b1 in range(0,n - B + 1):
                for a2 in range(n - B,n):
                    for b2 in range(n - B,m):
                        subMatrixSum = 0
                        subMatrixSum += A[a2][b2]
                        if b1 > 0:
                            subMatrixSum -= A[a2][b1 - 1]
                        if a1 > 0:
                            subMatrixSum -= A[a1 - 1][b2]
                        if a1 > 0 and b1 > 0:
                            subMatrixSum += A[a1 - 1][b1 - 1]
                        maxSum = max(maxSum,subMatrixSum % 1000000007)
        return maxSum
